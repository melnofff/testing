import pytest
import pandas as pd
import time
from cloud_client import CloudDataClient
from cloud_pipeline import CloudDataPipeline
import os

class TestCloudPipeline:
    def setup_method(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ç–µ—Å—Ç–æ–º"""
        # –ó–∞–ø—É—Å–∫–∞–µ–º LocalStack –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—É—â–µ–Ω
        self.start_localstack_if_needed()
        
        self.client = CloudDataClient(use_localstack=True)
        self.pipeline = CloudDataPipeline(use_localstack=True)
        
    def start_localstack_if_needed(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º LocalStack –µ—Å–ª–∏ –æ–Ω –Ω–µ –∑–∞–ø—É—â–µ–Ω"""
        try:
            import requests
            response = requests.get("http://localhost:4566/health")
            if response.status_code != 200:
                print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º LocalStack...")
                os.system("docker-compose up -d")
                time.sleep(10)
        except:
            print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º LocalStack...")
            os.system("docker-compose up -d")
            time.sleep(10)
    
    def test_s3_operations(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å S3"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π bucket
        bucket_name = "test-s3-bucket"
        assert self.client.create_bucket(bucket_name)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = pd.DataFrame({
            'id': [1, 2, 3],
            'name': ['Test1', 'Test2', 'Test3']
        })
        
        assert self.client.upload_csv_to_s3(test_data, bucket_name, "test.csv")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω
        files = self.client.list_bucket_files(bucket_name)
        assert "test.csv" in files
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
        downloaded_data = self.client.download_csv_from_s3(bucket_name, "test.csv")
        assert downloaded_data is not None
        assert len(downloaded_data) == 3
        assert list(downloaded_data.columns) == ['id', 'name']
    
    def test_sqs_operations(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å SQS"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –æ—á–µ—Ä–µ–¥—å
        queue_url = self.client.create_queue("test-sqs-queue")
        assert queue_url is not None
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        test_message = {"test": "data", "value": 123}
        message_id = self.client.send_message(queue_url, test_message)
        assert message_id is not None
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages = self.client.receive_messages(queue_url)
        assert len(messages) == 1
        assert messages[0]['body'] == test_message
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        assert self.client.delete_message(queue_url, messages[0]['receipt_handle'])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞
        messages_after = self.client.receive_messages(queue_url)
        assert len(messages_after) == 0
    
    def test_data_generation(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        data = self.pipeline.generate_sample_data(10)
        
        assert data is not None
        assert len(data) == 10
        assert 'employee_id' in data.columns
        assert 'name' in data.columns
        assert 'department' in data.columns
        assert 'salary' in data.columns
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
        assert data['salary'].min() >= 30000
        assert data['salary'].max() <= 100000
    
    def test_data_processing(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö"""
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        raw_data = self.pipeline.generate_sample_data(5)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.pipeline.upload_raw_data(raw_data, "test_processing.csv")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        success = self.pipeline.process_data("test_processing.csv", "test_processed.csv")
        assert success
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–∑–¥–∞–Ω—ã
        processed_files = self.client.list_bucket_files(self.pipeline.processed_bucket)
        assert any("test_processed.csv" in f for f in processed_files)
        assert "stats/department_stats.csv" in processed_files
    
    def test_pipeline_integration(self):
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å –º–∞–ª—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö
        self.pipeline.run_full_pipeline()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω—ã—Ö bucket'–∞—Ö
        raw_files = self.client.list_bucket_files(self.pipeline.raw_bucket)
        processed_files = self.client.list_bucket_files(self.pipeline.processed_bucket)
        
        assert len(raw_files) > 0
        assert len(processed_files) > 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        assert any("department_stats.csv" in f for f in processed_files)
    
    def test_error_handling(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫"""
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–∫–∞—á–∞—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        result = self.client.download_csv_from_s3("non-existent-bucket", "non-existent-file.csv")
        assert result is None
        
        # –ü—ã—Ç–∞–µ–º—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –æ—á–µ—Ä–µ–¥—å
        result = self.client.send_message("invalid-queue-url", {"test": "data"})
        assert result is None

if __name__ == "__main__":
    pytest.main([__file__, "-v"])