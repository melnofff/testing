import pandas as pd
from cloud_client import CloudDataClient
import time
from datetime import datetime
import json

class CloudDataPipeline:
    def __init__(self, use_localstack=True):
        self.client = CloudDataClient(use_localstack)
        self.setup_infrastructure()
    
    def setup_infrastructure(self):
        """–°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
        print("üèóÔ∏è –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±–ª–∞—á–Ω—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
        
        # –°–æ–∑–¥–∞–µ–º S3 bucket –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.raw_bucket = "raw-data-bucket"
        self.client.create_bucket(self.raw_bucket)
        
        # –°–æ–∑–¥–∞–µ–º S3 bucket –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self.processed_bucket = "processed-data-bucket" 
        self.client.create_bucket(self.processed_bucket)
        
        # –°–æ–∑–¥–∞–µ–º SQS –æ—á–µ—Ä–µ–¥—å –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
        self.notification_queue = self.client.create_queue("data-processing-queue")
        
        print("‚úÖ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")
    
    def generate_sample_data(self, num_records=100):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        print(f"üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {num_records} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π...")
        
        import random
        departments = ['IT', 'HR', 'Finance', 'Marketing', 'Sales']
        
        data = []
        for i in range(num_records):
            record = {
                'employee_id': i + 1,
                'name': f'Employee_{i+1}',
                'department': random.choice(departments),
                'salary': random.randint(30000, 100000),
                'join_date': f'202{random.randint(0,3)}-{random.randint(1,12):02d}-{random.randint(1,28):02d}',
                'performance_score': round(random.uniform(1.0, 5.0), 2)
            }
            data.append(record)
        
        dataframe = pd.DataFrame(data)
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(dataframe)} –∑–∞–ø–∏—Å–µ–π")
        return dataframe
    
    def upload_raw_data(self, dataframe, filename):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ S3"""
        print(f"üì§ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ {self.raw_bucket}...")
        
        success = self.client.upload_csv_to_s3(
            dataframe, self.raw_bucket, f"raw/{filename}"
        )
        
        if success:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
            notification = {
                'event_type': 'RAW_DATA_UPLOADED',
                'bucket': self.raw_bucket,
                'filename': f"raw/{filename}",
                'timestamp': datetime.now().isoformat(),
                'record_count': len(dataframe)
            }
            self.client.send_message(self.notification_queue, notification)
        
        return success
    
    def process_data(self, input_filename, output_filename):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ: —á–∏—Å—Ç–∏–º –∏ –æ–±–æ–≥–∞—â–∞–µ–º"""
        print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ: {input_filename} -> {output_filename}")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        raw_data = self.client.download_csv_from_s3(
            self.raw_bucket, f"raw/{input_filename}"
        )
        
        if raw_data is None:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return False
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
        processed_data = raw_data.copy()
        
        # 1. –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø–æ–ª—è
        processed_data['salary_category'] = processed_data['salary'].apply(
            lambda x: 'Low' if x < 50000 else 'Medium' if x < 80000 else 'High'
        )
        
        processed_data['experience_years'] = 2024 - pd.to_datetime(
            processed_data['join_date']
        ).dt.year
        
        # 2. –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        processed_data['name'] = processed_data['name'].str.strip()
        
        # 3. –î–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        dept_stats = processed_data.groupby('department').agg({
            'salary': ['mean', 'min', 'max'],
            'performance_score': 'mean'
        }).round(2)
        
        dept_stats.columns = ['avg_salary', 'min_salary', 'max_salary', 'avg_performance']
        dept_stats = dept_stats.reset_index()
        
        print("‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        success1 = self.client.upload_csv_to_s3(
            processed_data, self.processed_bucket, f"processed/{output_filename}"
        )
        
        success2 = self.client.upload_csv_to_s3(
            dept_stats, self.processed_bucket, f"stats/department_stats.csv"
        )
        
        if success1 and success2:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ–±—Ä–∞–±–æ—Ç–∫–µ
            notification = {
                'event_type': 'DATA_PROCESSED',
                'input_file': input_filename,
                'output_file': output_filename,
                'timestamp': datetime.now().isoformat(),
                'record_count': len(processed_data)
            }
            self.client.send_message(self.notification_queue, notification)
        
        return success1 and success2
    
    def monitor_queue(self, duration_seconds=30):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–º –æ—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π"""
        print(f"üëÄ –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –æ—á–µ—Ä–µ–¥—å –≤ —Ç–µ—á–µ–Ω–∏–µ {duration_seconds} —Å–µ–∫—É–Ω–¥...")
        
        start_time = time.time()
        messages_processed = 0
        
        while time.time() - start_time < duration_seconds:
            messages = self.client.receive_messages(self.notification_queue)
            
            for msg in messages:
                message_body = msg['body']
                print(f"üì® –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {message_body['event_type']}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Å–æ–æ–±—â–µ–Ω–∏–π
                if message_body['event_type'] == 'RAW_DATA_UPLOADED':
                    print(f"   üìä –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ: {message_body['filename']}")
                    print(f"   üìà –ó–∞–ø–∏—Å–µ–π: {message_body['record_count']}")
                
                elif message_body['event_type'] == 'DATA_PROCESSED':
                    print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ: {message_body['input_file']} -> {message_body['output_file']}")
                
                # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                self.client.delete_message(self.notification_queue, msg['receipt_handle'])
                messages_processed += 1
            
            time.sleep(2)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
        
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {messages_processed}")
        return messages_processed
    
    def run_full_pipeline(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω"""
        print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π –æ–±–ª–∞—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω...")
        
        # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        sample_data = self.generate_sample_data(50)
        
        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        input_filename = f"employees_{timestamp}.csv"
        self.upload_raw_data(sample_data, input_filename)
        
        # 3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        output_filename = f"processed_employees_{timestamp}.csv"
        self.process_data(input_filename, output_filename)
        
        # 4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–º –æ—á–µ—Ä–µ–¥—å
        self.monitor_queue(10)
        
        # 5. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ê–ô–ü–õ–ê–ô–ù–ê:")
        print(f"üìÅ –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ: {self.client.list_bucket_files(self.raw_bucket)}")
        print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {self.client.list_bucket_files(self.processed_bucket)}")
        
        print("üéâ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω!")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω —Å LocalStack
    pipeline = CloudDataPipeline(use_localstack=True)
    pipeline.run_full_pipeline()