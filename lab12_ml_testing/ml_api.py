from flask import Flask, request, jsonify
import pandas as pd
from ml_pipeline import MLPipeline
import joblib
import os
from datetime import datetime

app = Flask(__name__)
pipeline = MLPipeline()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    print("üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª—å...")
    success = pipeline.load_model('model')
    if success:
        print("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å—Ä–∞–∑—É –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
load_model()

@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'model_loaded': pipeline.model is not None
    })

@app.route('/predict', methods=['POST'])
def predict():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()

        if not data:
            return jsonify({'error': 'No data provided'}), 400

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if pipeline.model is None:
            return jsonify({'error': 'Model not loaded'}), 503

        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        predictions = pipeline.predict(data)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'predictions': predictions,
            'timestamp': datetime.now().isoformat(),
            'model_version': '1.0'
        }

        return jsonify(response)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/batch_predict', methods=['POST'])
def batch_predict():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –±–∞—Ç—á–µ–≤—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    try:
        data = request.get_json()

        if not data or 'customers' not in data:
            return jsonify({'error': 'No customers data provided'}), 400

        customers = data['customers']

        if not isinstance(customers, list):
            return jsonify({'error': 'Customers should be a list'}), 400

        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = pipeline.predict(customers)

        response = {
            'predictions': predictions,
            'total_customers': len(customers),
            'timestamp': datetime.now().isoformat()
        }

        return jsonify(response)

    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/model_info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    if pipeline.model is None:
        return jsonify({'error': 'Model not loaded'}), 503

    feature_importance = None
    if hasattr(pipeline.model, 'feature_importances_'):
        feature_importance = dict(zip(pipeline.feature_columns, pipeline.model.feature_importances_))

    return jsonify({
        'feature_columns': pipeline.feature_columns,
        'target_column': pipeline.target_column,
        'feature_importance': feature_importance,
        'model_type': type(pipeline.model).__name__
    })

if __name__ == '__main__':
    print("üéØ –ó–∞–ø—É—Å–∫–∞–µ–º ML API...")
    print("üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:")
    print("   GET  /health        - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è")
    print("   POST /predict       - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞")
    print("   POST /batch_predict - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print("   GET  /model_info    - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
    print("\nüåê API –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://localhost:5000")
    app.run(debug=True, host='0.0.0.0', port=5000)
