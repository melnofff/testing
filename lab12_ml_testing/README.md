# Лабораторная работа 12: Комплексное тестирование ML Pipeline

## Описание проекта

Полная система для тестирования ML Pipeline, включающая:
- Обучение модели машинного обучения для предсказания оттока клиентов (churn prediction)
- Flask API для инференса
- Комплексное тестирование качества данных, модели и API
- Мониторинг стабильности модели и дрифта данных
- Автоматизированные pytest тесты

## Структура проекта

```
lab12_ml_testing/
├── ml_pipeline.py              # ML pipeline для обучения и предсказаний
├── ml_api.py                   # Flask API для инференса
├── ml_testing_framework.py     # Фреймворк для тестирования ML pipeline
├── ml_monitoring.py            # Система мониторинга ML pipeline
├── run_ml_system.py           # Главный скрипт для запуска всей системы
├── train_model.py             # Вспомогательный скрипт для обучения модели
├── tests/
│   └── test_ml_pipeline.py    # Pytest тесты
├── model/                      # Обученная модель (создаётся автоматически)
│   ├── model.joblib
│   ├── label_encoders.joblib
│   └── feature_info.joblib
├── requirements.txt            # Зависимости проекта
├── ml_testing_report.json     # Отчёт тестирования (создаётся)
├── ml_monitoring_report.json  # Отчёт мониторинга (создаётся)
└── ml_monitoring_dashboard.png # Дашборд мониторинга (создаётся)
```

## Компоненты ML Pipeline

### 1. Качество данных
- Проверка обязательных колонок
- Проверка пропущенных значений
- Проверка выбросов
- Проверка распределения целевой переменной

### 2. Производительность модели
- Accuracy (точность)
- Precision (точность положительных предсказаний)
- Recall (полнота)
- F1-score (гармоническое среднее)

### 3. Справедливость модели
- Проверка предсказаний по возрастным группам
- Обнаружение дискриминации

### 4. API функциональность
- Health check
- Одиночные предсказания
- Батчевые предсказания

### 5. Дрифт данных
- Проверка изменений в данных с помощью Evidently
- Мониторинг стабильности модели

## Установка и запуск

### 1. Установка зависимостей

```bash
cd lab12_ml_testing
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

pip install -r requirements.txt
```

### 2. Обучение модели

```bash
python train_model.py
```

**Результат:**
- Модель сохраняется в папку `model/`
- Точность: ~77% на тестовых данных

### 3. Запуск API

```bash
python ml_api.py
```

API доступен по адресу: http://localhost:5000

**Доступные эндпоинты:**
- `GET /health` - Проверка состояния API
- `POST /predict` - Предсказание для одного клиента
- `POST /batch_predict` - Предсказание для нескольких клиентов
- `GET /model_info` - Информация о модели

### 4. Тестирование API (примеры запросов)

**Health check:**
```bash
curl http://localhost:5000/health
```

**Предсказание:**
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": "TEST_001",
    "age": 35,
    "tenure": 24,
    "monthly_charges": 75.50,
    "total_charges": 1812.00,
    "contract_type": "Monthly",
    "payment_method": "Credit Card",
    "paperless_billing": 1,
    "dependents": 0,
    "partner": 1,
    "online_security": 1,
    "tech_support": 1,
    "monthly_usage_gb": 250,
    "customer_service_calls": 2
  }'
```

### 5. Запуск тестов

**Pytest тесты:**
```bash
python -m pytest tests/ -v
```

**Полное тестирование ML pipeline:**
```bash
# Сначала запустите API в отдельном терминале
python ml_api.py

# Затем в другом терминале
python ml_testing_framework.py
```

### 6. Мониторинг

```bash
python ml_monitoring.py
```

**Результат:**
- Создаётся дашборд: `ml_monitoring_dashboard.png`
- Создаётся отчёт: `ml_monitoring_report.json`

### 7. Полная система

```bash
python run_ml_system.py
```

Запускает всё автоматически:
1. Обучение модели
2. Запуск API
3. Тестирование
4. Мониторинг

## Результаты тестирования

### Pytest тесты
✅ **7/7 тестов пройдено (100%)**

### ML Pipeline тестирование
✅ **13/13 тестов пройдено (100%)**

**Категории:**
- DATA: 100%
- MODEL: 100%
- API: 100%

### Мониторинг
- Средняя точность: **78.5%**
- Максимальный дрифт: **4.0%**
- Стабильность: **70.5%** (средняя стабильность)

## Проблемы и решения

### 1. Проблема с `@app.before_first_request` в Flask 2.3.0
**Ошибка:** `AttributeError: 'Flask' object has no attribute 'before_first_request'`

**Причина:** В Flask 2.3.0+ декоратор `@app.before_first_request` был удалён

**Решение:** Заменили на прямой вызов функции `load_model()` при импорте модуля

### 2. Проблема с кодировкой эмодзи в Windows
**Ошибка:** `UnicodeEncodeError: 'charmap' codec can't encode character '\U0001f4ca'`

**Причина:** Windows консоль использует кодировку cp1251, которая не поддерживает эмодзи

**Решение:** Создали вспомогательный скрипт `train_model.py` с настройкой UTF-8 через `io.TextIOWrapper`

### 3. Проблема с JSON сериализацией numpy типов
**Ошибка:** `TypeError: Object of type int64 is not JSON serializable`

**Причина:** Pandas/numpy используют специальные типы (int64, float64), которые не сериализуются в JSON

**Решение:**
- Добавили приведение типов: `int()`, `float()`
- Добавили параметр `default=str` в `json.dump()`
- Указали кодировку `encoding='utf-8'` при открытии файлов

### 4. Ошибка в тесте справедливости модели
**Ошибка:** `Length of values (200) does not match length of index (1000)`

**Причина:** Предсказания делались только для тестовой выборки (200 записей), но применялись к полному датасету (1000 записей)

**Решение:** Используем только подмножество данных: `data_subset = data.iloc[:len(predictions)].copy()`

### 5. Проблема с Evidently тестами
**Ошибка:** `name 'TestNumColumnsMean' is not defined`

**Причина:** В версии Evidently 0.3.0 некоторые тесты имеют другие названия или отсутствуют

**Решение:** Обновили импорты и использовали только доступные тесты: `TestNumberOfColumns()`, `TestColumnsType()`, `TestShareOfMissingValues()`

### 6. Ошибка в тесте дрифта данных
**Ошибка:** Тест провалился из-за разного количества строк (1000 vs 200)

**Причина:** Тест `TestNumberOfRows()` сравнивает количество строк, которое специально разное

**Решение:** Убрали `TestNumberOfRows()` из набора тестов, так как размеры выборок могут отличаться

### 7. Неправильный тест предобработки данных
**Ошибка:** Тест ожидал, что категориальные колонки исчезнут после кодирования

**Причина:** `LabelEncoder` не меняет названия колонок, только преобразует значения в числа

**Решение:** Изменили тест, чтобы проверять наличие колонок и числовой тип данных

### 8. API тесты провалились при первом запуске
**Ошибка:** `Failed to establish a new connection: [WinError 10061]`

**Причина:** API не был запущен во время выполнения тестов

**Решение:** Нужно сначала запустить API в отдельном терминале, затем запускать тесты (или использовать `run_ml_system.py` который запускает всё автоматически)

## Глоссарий

### Сериализация (Serialization)
Процесс преобразования объекта в формат для сохранения/передачи.

**Пример:**
```python
data = {'name': 'Иван', 'age': 25}
json_string = json.dumps(data)  # Сериализация в JSON строку
```

### Декоратор (Decorator)
Функция, которая "оборачивает" другую функцию, добавляя функциональность.

**Пример:**
```python
@app.route('/hello')
def hello():
    return "Привет!"
```

### Дрифт данных (Data Drift)
Изменение статистических свойств данных со временем.

### Инференс (Inference)
Процесс получения предсказаний от обученной модели.

## Рекомендации по улучшению

1. **Увеличить точность модели:**
   - Увеличить количество данных для обучения
   - Настроить гиперпараметры Random Forest
   - Попробовать другие алгоритмы (XGBoost, LightGBM)

2. **Улучшить мониторинг:**
   - Добавить алерты в Telegram/Email
   - Настроить автоматическое переобучение при дрифте
   - Добавить больше метрик бизнес-качества

3. **Расширить тестирование:**
   - Добавить нагрузочное тестирование API
   - Добавить интеграционные тесты
   - Настроить CI/CD pipeline

## Автор Danila Melnikov

Выполнено в рамках лабораторной работы 12 по курсу "Тестирование"

Учебный проект
