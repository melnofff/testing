import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
import joblib
from datetime import datetime
import os

class MLPipeline:
    def __init__(self):
        self.model = None
        self.label_encoders = {}
        self.feature_columns = []
        self.target_column = 'churn'

    def generate_sample_data(self, num_samples=1000):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        print(f"üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {num_samples} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π...")

        np.random.seed(42)
        data = []

        for i in range(num_samples):
            record = {
                'customer_id': f"CUST_{i:06d}",
                'age': np.random.randint(18, 70),
                'tenure': np.random.randint(1, 60),  # –º–µ—Å—è—Ü–µ–≤
                'monthly_charges': round(np.random.uniform(20, 100), 2),
                'total_charges': round(np.random.uniform(50, 5000), 2),
                'contract_type': np.random.choice(['Monthly', 'Yearly', 'Two-Year'], p=[0.4, 0.4, 0.2]),
                'payment_method': np.random.choice(['Credit Card', 'Bank Transfer', 'Electronic Check'], p=[0.3, 0.3, 0.4]),
                'paperless_billing': np.random.choice([0, 1], p=[0.4, 0.6]),
                'dependents': np.random.choice([0, 1], p=[0.7, 0.3]),
                'partner': np.random.choice([0, 1], p=[0.6, 0.4]),
                'online_security': np.random.choice([0, 1], p=[0.5, 0.5]),
                'tech_support': np.random.choice([0, 1], p=[0.5, 0.5]),
                'monthly_usage_gb': np.random.randint(50, 500),
                'customer_service_calls': np.random.randint(0, 10),
                'churn': 0  # –ë—É–¥–µ–º –≤—ã—á–∏—Å–ª—è—Ç—å –Ω–∏–∂–µ
            }
            data.append(record)

        df = pd.DataFrame(data)

        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        # –ö–ª–∏–µ–Ω—Ç—ã —Å –±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é —É—Ö–æ–¥—è—Ç –ø—Ä–∏:
        # - –≤—ã—Å–æ–∫–∏—Ö monthly_charges
        # - –º–Ω–æ–≥–æ –∑–≤–æ–Ω–∫–æ–≤ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É
        # - –º–µ—Å—è—á–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞–∫—Ç
        # - –Ω–µ—Ç online_security –∏ tech_support
        churn_probability = (
            df['monthly_charges'] / 100 * 0.3 +
            df['customer_service_calls'] / 10 * 0.3 +
            (df['contract_type'] == 'Monthly').astype(int) * 0.2 +
            (df['online_security'] == 0).astype(int) * 0.1 +
            (df['tech_support'] == 0).astype(int) * 0.1
        )

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
        churn_probability += np.random.normal(0, 0.1, len(df))

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –±–∏–Ω–∞—Ä–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        df['churn'] = (churn_probability > 0.5).astype(int)

        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
        print(df['churn'].value_counts(normalize=True))

        return df

    def preprocess_data(self, df):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        print("üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")

        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        processed_df = df.copy()

        # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        categorical_columns = ['contract_type', 'payment_method']

        for col in categorical_columns:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                processed_df[col] = self.label_encoders[col].fit_transform(processed_df[col])
            else:
                processed_df[col] = self.label_encoders[col].transform(processed_df[col])

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏—á–∏ –∏ —Ç–∞—Ä–≥–µ—Ç
        self.feature_columns = [col for col in processed_df.columns
                               if col not in ['customer_id', self.target_column]]

        X = processed_df[self.feature_columns]
        y = processed_df[self.target_column]

        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {len(self.feature_columns)} —Ñ–∏—á–µ–π")

        return X, y

    def train_model(self, X, y, test_size=0.2):
        """–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å"""
        print("üéØ –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å...")

        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )

        self.model.fit(X_train, y_train)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        train_score = self.model.score(X_train, y_train)
        test_score = self.model.score(X_test, y_test)

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
        print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {train_score:.3f}")
        print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {test_score:.3f}")

        # –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        y_pred = self.model.predict(X_test)
        print("\nüìà –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç:")
        print(classification_report(y_test, y_pred))

        return X_test, y_test, y_pred

    def save_model(self, path='model'):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —ç–Ω–∫–æ–¥–µ—Ä—ã"""
        print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å...")
        os.makedirs(path, exist_ok=True)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        joblib.dump(self.model, f'{path}/model.joblib')

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–Ω–∫–æ–¥–µ—Ä—ã
        joblib.dump(self.label_encoders, f'{path}/label_encoders.joblib')

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏—á–∞—Ö
        feature_info = {
            'feature_columns': self.feature_columns,
            'target_column': self.target_column,
            'timestamp': datetime.now().isoformat()
        }
        joblib.dump(feature_info, f'{path}/feature_info.joblib')

        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ø–∞–ø–∫—É {path}")

    def load_model(self, path='model'):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —ç–Ω–∫–æ–¥–µ—Ä—ã"""
        print("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...")
        try:
            self.model = joblib.load(f'{path}/model.joblib')
            self.label_encoders = joblib.load(f'{path}/label_encoders.joblib')
            feature_info = joblib.load(f'{path}/feature_info.joblib')
            self.feature_columns = feature_info['feature_columns']
            self.target_column = feature_info['target_column']
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def predict(self, input_data):
        """–î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if self.model is None:
            raise Exception("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if isinstance(input_data, dict):
            # –û–¥–Ω–∞ –∑–∞–ø–∏—Å—å
            input_df = pd.DataFrame([input_data])
        else:
            # –ù–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π
            input_df = pd.DataFrame(input_data)

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        processed_df = input_df.copy()

        for col in self.label_encoders:
            if col in processed_df.columns:
                # –î–ª—è –Ω–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                unknown_categories = ~processed_df[col].isin(self.label_encoders[col].classes_)
                if unknown_categories.any():
                    most_frequent = self.label_encoders[col].classes_[0]
                    processed_df.loc[unknown_categories, col] = most_frequent

                processed_df[col] = self.label_encoders[col].transform(processed_df[col])

        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ –≤—Å–µ —Ñ–∏—á–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
        for col in self.feature_columns:
            if col not in processed_df.columns:
                processed_df[col] = 0  # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ñ–∏—á–∏

        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        X = processed_df[self.feature_columns]
        predictions = self.model.predict(X)
        probabilities = self.model.predict_proba(X)

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        results = []
        for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
            result = {
                'prediction': int(pred),
                'probability': float(prob[1]),  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1 (churn)
                'customer_id': input_df.iloc[i]['customer_id'] if 'customer_id' in input_df.columns else f"cust_{i}"
            }
            results.append(result)

        return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    pipeline = MLPipeline()

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    data = pipeline.generate_sample_data(1000)

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    X, y = pipeline.preprocess_data(data)
    pipeline.train_model(X, y)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    pipeline.save_model()

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    test_customer = {
        'customer_id': 'TEST_001',
        'age': 35,
        'tenure': 24,
        'monthly_charges': 75.50,
        'total_charges': 1812.00,
        'contract_type': 'Monthly',
        'payment_method': 'Credit Card',
        'paperless_billing': 1,
        'dependents': 0,
        'partner': 1,
        'online_security': 1,
        'tech_support': 1,
        'monthly_usage_gb': 250,
        'customer_service_calls': 2
    }

    prediction = pipeline.predict(test_customer)
    print(f"\nüéØ –¢–µ—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction}")
