import time
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from ml_pipeline import MLPipeline
from ml_testing_framework import MLTestingFramework
import matplotlib.pyplot as plt
import json
import os

class MLMonitoring:
    def __init__(self):
        self.pipeline = MLPipeline()
        self.tester = MLTestingFramework()
        self.monitoring_data = []
        self.alert_threshold = 0.7  # –ü–æ—Ä–æ–≥ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤

    def collect_monitoring_data(self, days=7, interval_hours=6):
        """–°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        print(f"üìä –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞ {days} –¥–Ω–µ–π...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        current_date = start_date
        iteration = 0

        while current_date <= end_date:
            iteration += 1
            print(f"\nüìÖ –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration}: {current_date.strftime('%Y-%m-%d %H:%M')}")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º "—Ç–µ–∫—É—â–∏–µ" –¥–∞–Ω–Ω—ã–µ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –±—Ä–∞–ª–∏ –±—ã –∏–∑ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞)
            current_data = self.pipeline.generate_sample_data(200)

            # –ï—Å–ª–∏ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å –º–æ–¥–µ–ª—å, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if self.pipeline.model is not None:
                # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                X_current, y_current = self.pipeline.preprocess_data(current_data)
                current_predictions = self.pipeline.model.predict(X_current)

                # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                from sklearn.metrics import accuracy_score
                current_accuracy = accuracy_score(y_current, current_predictions)

                # –°–æ–±–∏—Ä–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                monitoring_point = {
                    'timestamp': current_date.isoformat(),
                    'data_size': len(current_data),
                    'accuracy': current_accuracy,
                    'churn_rate': current_data['churn'].mean(),
                    'feature_drift': self.calculate_feature_drift(current_data),
                    'alerts': []
                }

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
                if current_accuracy < self.alert_threshold:
                    monitoring_point['alerts'].append(f"–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {current_accuracy:.3f}")

                if monitoring_point['feature_drift'] > 0.1:
                    monitoring_point['alerts'].append(f"–í—ã—Å–æ–∫–∏–π –¥—Ä–∏—Ñ—Ç —Ñ–∏—á: {monitoring_point['feature_drift']:.3f}")

                self.monitoring_data.append(monitoring_point)

                print(f"   üìà Accuracy: {current_accuracy:.3f}")
                print(f"   üìä Churn rate: {monitoring_point['churn_rate']:.3f}")
                print(f"   üìâ Feature drift: {monitoring_point['feature_drift']:.3f}")

                if monitoring_point['alerts']:
                    print(f"   üö® Alerts: {', '.join(monitoring_point['alerts'])}")

            # "–ü–µ—Ä–µ–º–µ—â–∞–µ–º—Å—è" –≤–ø–µ—Ä–µ–¥ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
            current_date += timedelta(hours=interval_hours)

        print(f"\n‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(self.monitoring_data)} —Ç–æ—á–µ–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
        return self.monitoring_data

    def calculate_feature_drift(self, current_data, reference_data=None):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥—Ä–∏—Ñ—Ç —Ñ–∏—á–µ–π"""
        if reference_data is None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å
            reference_data = self.pipeline.generate_sample_data(500)

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∏—á–µ–π
        drift_score = 0
        key_features = ['age', 'monthly_charges', 'tenure']

        for feature in key_features:
            # KS test –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Ñ–∏—á–µ–π
            from scipy.stats import ks_2samp
            stat, _ = ks_2samp(reference_data[feature], current_data[feature])
            drift_score += stat

        return drift_score / len(key_features)

    def create_monitoring_dashboard(self):
        """–°–æ–∑–¥–∞–µ–º –¥–∞—à–±–æ—Ä–¥ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        if not self.monitoring_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞")
            return

        df = pd.DataFrame(self.monitoring_data)
        df['timestamp'] = pd.to_datetime(df['timestamp'])

        print("\nüìä –°–û–ó–î–ê–ï–ú –î–ê–®–ë–û–†–î –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê")

        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏
        plt.figure(figsize=(15, 10))

        # 1. –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
        plt.subplot(2, 2, 1)
        plt.plot(df['timestamp'], df['accuracy'], marker='o', linewidth=2)
        plt.axhline(y=self.alert_threshold, color='red', linestyle='--', label='–ü–æ—Ä–æ–≥ –∞–ª–µ—Ä—Ç–∞')
        plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏')
        plt.xlabel('–í—Ä–µ–º—è')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)

        # 2. –î—Ä–∏—Ñ—Ç —Ñ–∏—á–µ–π –≤–æ –≤—Ä–µ–º–µ–Ω–∏
        plt.subplot(2, 2, 2)
        plt.plot(df['timestamp'], df['feature_drift'], marker='s', color='orange', linewidth=2)
        plt.axhline(y=0.1, color='red', linestyle='--', label='–ü–æ—Ä–æ–≥ –¥—Ä–∏—Ñ—Ç–∞')
        plt.title('–î—Ä–∏—Ñ—Ç —Ñ–∏—á–µ–π –≤–æ –≤—Ä–µ–º–µ–Ω–∏')
        plt.xlabel('–í—Ä–µ–º—è')
        plt.ylabel('Feature Drift Score')
        plt.legend()
        plt.grid(True)
        plt.xticks(rotation=45)

        # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ churn rate
        plt.subplot(2, 2, 3)
        plt.hist(df['churn_rate'], bins=10, alpha=0.7, color='green')
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Churn Rate')
        plt.xlabel('Churn Rate')
        plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        plt.grid(True)

        # 4. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–ª–µ—Ä—Ç–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        plt.subplot(2, 2, 4)
        alert_counts = df['alerts'].apply(len)
        plt.bar(df['timestamp'], alert_counts, color='red', alpha=0.7)
        plt.title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–ª–µ—Ä—Ç–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏')
        plt.xlabel('–í—Ä–µ–º—è')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–ª–µ—Ä—Ç–æ–≤')
        plt.grid(True)
        plt.xticks(rotation=45)

        plt.tight_layout()
        plt.savefig('ml_monitoring_dashboard.png', dpi=300, bbox_inches='tight')
        plt.close()

        print("‚úÖ –î–∞—à–±–æ—Ä–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ ml_monitoring_dashboard.png")

    def generate_monitoring_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        if not self.monitoring_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç—á–µ—Ç–∞")
            return None

        df = pd.DataFrame(self.monitoring_data)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_alerts = df['alerts'].apply(len).sum()
        avg_accuracy = df['accuracy'].mean()
        max_drift = df['feature_drift'].max()

        print("\nüìà –û–¢–ß–ï–¢ –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê ML PIPELINE")
        print("=" * 50)
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {len(df)} —Ç–æ—á–µ–∫")
        print(f"üéØ –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {avg_accuracy:.3f}")
        print(f"üìâ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥—Ä–∏—Ñ—Ç: {max_drift:.3f}")
        print(f"üö® –í—Å–µ–≥–æ –∞–ª–µ—Ä—Ç–æ–≤: {total_alerts}")

        # –î–µ—Ç–∞–ª–∏ –∞–ª–µ—Ä—Ç–æ–≤
        if total_alerts > 0:
            print(f"\nüîç –î–ï–¢–ê–õ–ò –ê–õ–ï–†–¢–û–í:")
            all_alerts = []
            for alerts in df['alerts']:
                all_alerts.extend(alerts)
            alert_counts = pd.Series(all_alerts).value_counts()
            for alert, count in alert_counts.items():
                print(f"  ‚Ä¢ {alert}: {count} —Ä–∞–∑")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report = {
            'timestamp': datetime.now().isoformat(),
            'monitoring_period': int(len(df)),
            'average_accuracy': float(avg_accuracy),
            'max_feature_drift': float(max_drift),
            'total_alerts': int(total_alerts),
            'stability_score': float(self.calculate_stability_score(df)),
            'monitoring_data': df.to_dict('records')
        }

        with open('ml_monitoring_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

        print(f"\n‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ ml_monitoring_report.json")

        # –û—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        stability = report['stability_score']
        if stability >= 0.8:
            print("üèÜ –í–´–°–û–ö–ê–Ø –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–¨: ML pipeline —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ")
        elif stability >= 0.6:
            print("‚ö†Ô∏è  –°–†–ï–î–ù–Ø–Ø –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–¨: ML pipeline —Ç—Ä–µ–±—É–µ—Ç –Ω–∞–±–ª—é–¥–µ–Ω–∏—è")
        else:
            print("üö® –ù–ò–ó–ö–ê–Ø –°–¢–ê–ë–ò–õ–¨–ù–û–°–¢–¨: ML pipeline –Ω–µ—Å—Ç–∞–±–∏–ª–µ–Ω, –Ω—É–∂–Ω—ã –¥–µ–π—Å—Ç–≤–∏—è")

        return report

    def calculate_stability_score(self, df):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ü–µ–Ω–∫—É —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ pipeline"""
        # –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏, –¥—Ä–∏—Ñ—Ç–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∞–ª–µ—Ä—Ç–æ–≤
        accuracy_score = df['accuracy'].mean()
        drift_penalty = min(df['feature_drift'].max() * 2, 0.3)  # –®—Ç—Ä–∞—Ñ –∑–∞ –¥—Ä–∏—Ñ—Ç
        alert_penalty = min(len(df[df['alerts'].apply(len) > 0]) / len(df), 0.3)  # –®—Ç—Ä–∞—Ñ –∑–∞ –∞–ª–µ—Ä—Ç—ã

        stability = accuracy_score - drift_penalty - alert_penalty
        return max(stability, 0)  # –ù–µ –Ω–∏–∂–µ 0

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    monitor = MLMonitoring()

    print("üéØ –ó–ê–ü–£–°–ö–ê–ï–ú –ú–û–ù–ò–¢–û–†–ò–ù–ì ML PIPELINE")
    print("=" * 50)

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    pipeline = MLPipeline()
    data = pipeline.generate_sample_data(1000)
    X, y = pipeline.preprocess_data(data)
    pipeline.train_model(X, y)
    pipeline.save_model()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    monitor.pipeline.load_model()

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    monitoring_data = monitor.collect_monitoring_data(days=3, interval_hours=4)

    # –°–æ–∑–¥–∞–µ–º –¥–∞—à–±–æ—Ä–¥ –∏ –æ—Ç—á–µ—Ç
    monitor.create_monitoring_dashboard()
    report = monitor.generate_monitoring_report()
