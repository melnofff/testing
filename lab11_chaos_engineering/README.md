# Лабораторная работа 11: Chaos Engineering для data-систем

## Описание проекта

Данный проект реализует систему тестирования отказоустойчивости data pipeline с использованием методов Chaos Engineering. Проект включает в себя фреймворк для проведения контролируемых экспериментов с хаосом, устойчивый data pipeline с механизмами восстановления, и систему мониторинга для оценки надежности.

## Структура проекта

```
lab11_chaos_engineering/
├── chaos_framework.py          # Фреймворк для проведения Chaos экспериментов
├── resilient_pipeline.py       # Устойчивый data pipeline с retry и circuit breaker
├── resilience_monitor.py       # Система мониторинга устойчивости
├── run_chaos_system.py         # Главный скрипт запуска всей системы
├── cloud_client.py             # Клиент для работы с облачными сервисами (S3, SQS)
├── cloud_pipeline.py           # Базовый pipeline для облачных операций
├── start_localstack.py         # Скрипты для работы с LocalStack
├── docker-compose.yml          # Конфигурация Docker для LocalStack
├── requirements.txt            # Зависимости проекта
├── tests/
│   └── test_chaos_engineering.py  # Тесты для системы Chaos Engineering
├── chaos_report.json           # Отчет по chaos экспериментам (генерируется)
├── resilience_report.json      # Отчет об устойчивости (генерируется)
└── resilience_metrics.png      # Графики метрик устойчивости (генерируется)
```

## Реализованные Chaos эксперименты

### 1. Network Latency (Сетевые задержки)
- **Описание**: Эмулирует задержки в сети путем добавления sleep в критические операции
- **Параметры**: 
  - `duration` - длительность эксперимента (секунды)
  - `latency_ms` - величина задержки (миллисекунды)
- **Цель**: Проверка устойчивости системы к сетевым задержкам

### 2. Service Failure (Отказ сервисов)
- **Описание**: Эмулирует полный отказ облачных сервисов (S3, SQS)
- **Параметры**:
  - `service_type` - тип сервиса (S3 или SQS)
  - `failure_duration` - длительность отказа (секунды)
- **Цель**: Проверка механизмов восстановления при отказе сервисов

### 3. High CPU Load (Высокая нагрузка на CPU)
- **Описание**: Создает искусственную нагрузку на процессор
- **Параметры**:
  - `duration` - длительность нагрузки
  - `load_percent` - целевая нагрузка на CPU (%)
- **Цель**: Тестирование производительности под нагрузкой

### 4. Memory Pressure (Давление на память)
- **Описание**: Резервирует большие объемы памяти
- **Параметры**:
  - `duration` - длительность эксперимента
  - `memory_mb` - объем резервируемой памяти (MB)
- **Цель**: Проверка поведения системы при ограниченной памяти

### 5. Data Corruption (Коррупция данных)
- **Описание**: Портит данные различными способами (null values, дубликаты, неверный формат)
- **Параметры**:
  - `probability` - вероятность коррупции данных (0.0-1.0)
- **Типы коррупции**:
  - Добавление null значений
  - Дублирование записей
  - Порча формата данных
  - Обрезка данных
- **Цель**: Проверка валидации и обработки некорректных данных

### 6. Chaos Monkey (Случайные сбои)
- **Описание**: Запускает случайные эксперименты через заданные интервалы
- **Параметры**:
  - `duration` - общая длительность работы
  - `interval` - интервал между экспериментами
- **Цель**: Комплексное тестирование устойчивости

## Устойчивый data pipeline

Pipeline реализован с использованием следующих паттернов отказоустойчивости:

### 1. Retry Mechanism (Механизм повторных попыток)
- **Реализация**: `upload_with_retry()`
- **Функционал**:
  - Автоматические повторные попытки при ошибках
  - Экспоненциальная backoff задержка (2^attempt секунд)
  - Настраиваемое количество попыток (по умолчанию 3)
  - Отправка неудачных операций в Dead Letter Queue

### 2. Circuit Breaker (Предохранитель)
- **Реализация**: `process_with_circuit_breaker()`
- **Функционал**:
  - Отслеживание последовательных ошибок
  - Открытие цепи после превышения порога ошибок (3 ошибки)
  - Автоматический сброс после timeout (30 секунд)
  - Предотвращение каскадных отказов

### 3. Dead Letter Queue (Очередь неудачных операций)
- **Функционал**:
  - Сохранение информации о неудачных операциях
  - Метаданные об ошибках (тип, время, количество попыток)
  - Возможность последующего анализа и обработки

### 4. Data Validation (Валидация данных)
- **Проверки**:
  - Наличие обязательных полей
  - Корректность типов данных
  - Уникальность идентификаторов
  - Валидация значений (положительные числа и т.д.)

## Результаты тестирования устойчивости

### Методология тестирования

Система тестировалась в течение нескольких циклов с включенным Chaos Engineering:

1. **Базовое тестирование** - проверка работы без хаоса
2. **Тестирование с хаосом** - запуск pipeline с активными chaos экспериментами
3. **Мониторинг метрик** - сбор данных об успешности, времени выполнения, retry попыток

### Метрики производительности

Система собирает следующие метрики:
- **Успешность пайплайна** - процент успешных выполнений
- **Время выполнения** - среднее время обработки данных
- **Количество retry** - число повторных попыток
- **Ошибки в DLQ** - количество неудачных операций в очереди
- **Chaos эксперименты** - число выполненных экспериментов

### Результаты

По результатам тестирования система показала:

✅ **Высокая устойчивость**: Pipeline продолжает работать даже при множественных сбоях
✅ **Эффективное восстановление**: Retry механизм успешно обрабатывает временные сбои
✅ **Graceful degradation**: Circuit breaker предотвращает каскадные отказы
✅ **Валидация данных**: Система отклоняет коррумпированные данные

## Выводы и рекомендации

### Выводы

1. **Chaos Engineering эффективен** - Контролируемые эксперименты помогли выявить слабые места системы до попадания в продакшен

2. **Retry + Circuit Breaker = Надежность** - Комбинация этих паттернов обеспечивает высокую устойчивость к временным сбоям

3. **Валидация критична** - Проверка данных на входе предотвращает распространение ошибок по системе

4. **Мониторинг необходим** - Без метрик невозможно оценить реальную устойчивость системы

### Рекомендации по улучшению

1. **Добавить health checks** 
   - Периодическая проверка доступности сервисов
   - Автоматическое переключение на резервные сервисы

2. **Расширить типы хаос-экспериментов**
   - Disk I/O задержки
   - Сетевые разрывы (packet loss)
   - Clock drift эксперименты

3. **Улучшить мониторинг**
   - Интеграция с системами алертинга (Prometheus, Grafana)
   - Real-time дашборды
   - Автоматические отчеты

4. **Оптимизировать параметры**
   - Тонкая настройка timeout значений
   - Адаптивный backoff (экспоненциальный с jitter)
   - Динамические пороги для circuit breaker

5. **Добавить персистентность**
   - Сохранение состояния pipeline
   - Возможность восстановления после полного сбоя

## Установка и запуск

### Требования

- Python 3.8+
- Docker и Docker Compose
- LocalStack (для эмуляции AWS сервисов)

### Установка зависимостей

```bash
pip install -r requirements.txt
```

### Запуск LocalStack

```bash
docker-compose up -d
```

### Запуск тестов

```bash
# Запуск всех тестов
python -m pytest tests/ -v

# Запуск отдельных компонентов
python chaos_framework.py          # Демо chaos фреймворка
python resilient_pipeline.py       # Демо устойчивого pipeline
python resilience_monitor.py       # Демо мониторинга

# Запуск полной системы
python run_chaos_system.py
```

## Использование

### Базовый пример - Chaos Framework

```python
from chaos_framework import ChaosFramework

chaos = ChaosFramework(use_localstack=True)

# Запуск отдельных экспериментов
chaos.network_latency(duration=15, latency_ms=800)
chaos.service_failure("S3", failure_duration=15)
chaos.high_cpu_load(duration=20, load_percent=60)
chaos.data_corruption(probability=0.5)

# Генерация отчета
chaos.generate_report()
```

### Устойчивый Pipeline

```python
from resilient_pipeline import ResilientDataPipeline

pipeline = ResilientDataPipeline(use_localstack=True)

# Запуск pipeline с chaos engineering
success = pipeline.run_resilient_pipeline(enable_chaos=True)
```

### Мониторинг

```python
from resilience_monitor import ResilienceMonitor

monitor = ResilienceMonitor(use_localstack=True)

# Сбор метрик в течение 5 минут
metrics = monitor.collect_metrics(duration=300, interval=30)

# Генерация отчета и визуализаций
report = monitor.generate_resilience_report()
```

## Технологии

- **Python** - основной язык разработки
- **Docker** - контейнеризация
- **LocalStack** - эмуляция AWS сервисов (S3, SQS)
- **pytest** - фреймворк для тестирования
- **pandas** - обработка данных
- **matplotlib** - визуализация метрик
- **psutil** - мониторинг системных ресурсов

## Авторы

Разработано в рамках курса по тестированию программного обеспечения.

## Лицензия

Учебный проект

---

**Примечание**: Для безопасного использования Chaos Engineering всегда проводите эксперименты в изолированной среде и с ограниченными параметрами!
